# Makine Ã–ÄŸrenmesi Ã–dev 1: Lojistik Regresyon

Bu proje, **NumPy** kullanarak sÄ±fÄ±rdan lojistik regresyon algoritmasÄ±nÄ± uygulayan eksiksiz bir makine Ã¶ÄŸrenmesi pipeline'Ä±dÄ±r. Proje, veri Ã¶n iÅŸleme, model eÄŸitimi, deÄŸerlendirme ve gÃ¶rselleÅŸtirme adÄ±mlarÄ±nÄ± iÃ§erir.

## ğŸ“‹ Ä°Ã§indekiler

[Proje YapÄ±sÄ±](#proje-yapÄ±sÄ±)
[Kurulum](#kurulum)
[KullanÄ±m](#kullanÄ±m)
[ModÃ¼llerin DetaylÄ± AÃ§Ä±klamasÄ±](#modÃ¼llerin-detaylÄ±-aÃ§Ä±klamasÄ±)
[Algoritma DetaylarÄ±](#algoritma-detaylarÄ±)
[SonuÃ§lar](#sonuÃ§lar)
[Notlar](#notlar)

## ğŸ—‚ï¸ Proje YapÄ±sÄ±

```
makine-ogrenmesi-hw1/
â”‚
â”œâ”€â”€ data/                            # Veri setleri
â”‚   â”œâ”€â”€ hw1Data.txt                  # Ham veri (101 Ã¶rnek, 2 Ã¶zellik, 1 etiket)
â”‚   â”œâ”€â”€ raw_train.npz                # Ham eÄŸitim verisi (%60)
â”‚   â”œâ”€â”€ raw_val.npz                  # Ham doÄŸrulama verisi (%20)
â”‚   â”œâ”€â”€ raw_test.npz                 # Ham test verisi (%20)
â”‚   â”œâ”€â”€ normalized_train.npz         # Normalize edilmiÅŸ eÄŸitim verisi
â”‚   â”œâ”€â”€ normalized_val.npz           # Normalize edilmiÅŸ doÄŸrulama verisi
â”‚   â””â”€â”€ normalized_test.npz          # Normalize edilmiÅŸ test verisi
â”‚
â”œâ”€â”€ docs/                            # DokÃ¼manlar
â”‚   â””â”€â”€ ML2025Hw1.pdf                # Ã–dev aÃ§Ä±klamasÄ± ve talimatlar
â”‚
â”œâ”€â”€ results/                         # SonuÃ§lar ve Ã§Ä±ktÄ±lar
â”‚   â”œâ”€â”€ evaluation/                  # DeÄŸerlendirme sonuÃ§larÄ±
â”‚   â”‚   â””â”€â”€ test_results.txt         # Test seti metrik sonuÃ§larÄ±
â”‚   â”œâ”€â”€ graphs/                      # Grafikler
â”‚   â”‚   â”œâ”€â”€ loss_curve.png           # EÄŸitim/doÄŸrulama kayÄ±p grafiÄŸi
â”‚   â”‚   â”œâ”€â”€ test_decision_boundary.png # Test verisi karar sÄ±nÄ±rÄ± grafiÄŸi
â”‚   â”‚   â”œâ”€â”€ train_decision_boundary.png # EÄŸitim verisi karar sÄ±nÄ±rÄ± grafiÄŸi
â”‚   â”‚   â”œâ”€â”€ tÃ¼m_scatter_plot.png     # TÃ¼m verinin scatter plot grafiÄŸi
â”‚   â”‚   â”œâ”€â”€ train_scatter_plot.png   # EÄŸitim verisinin scatter plot grafiÄŸi
â”‚   â”‚   â””â”€â”€ val_decision_boundary.png   # DoÄŸrulama verisi karar sÄ±nÄ±rÄ± grafiÄŸi
â”‚   â”œâ”€â”€ logs/                        # EÄŸitim loglarÄ±
â”‚   â”‚   â””â”€â”€ training.log             # Epoch bazlÄ± eÄŸitim loglarÄ±
â”‚   â””â”€â”€ model/                       # EÄŸitilmiÅŸ model aÄŸÄ±rlÄ±klarÄ±
â”‚       â”œâ”€â”€ model_weights_*.npy      # Zaman damgalÄ± model dosyalarÄ±
â”‚       â””â”€â”€ model_weights_latest.npy # En son eÄŸitilmiÅŸ model
â”‚
â”œâ”€â”€ src/                             # Kaynak kod
â”‚   â”œâ”€â”€ dataset.py                   # Veri yÃ¼kleme ve Ã¶n iÅŸleme
â”‚   â”œâ”€â”€ model.py                     # Lojistik regresyon modeli
â”‚   â”œâ”€â”€ train.py                     # Model eÄŸitimi
â”‚   â”œâ”€â”€ eval.py                      # Model deÄŸerlendirme
â”‚   â”œâ”€â”€ metrics.py                   # DeÄŸerlendirme metrikleri
â”‚   â”œâ”€â”€ logger.py                    # BirleÅŸik loglama sistemi
â”‚   â””â”€â”€ utils.py                     # YardÄ±mcÄ± fonksiyonlar
â”‚
â”œâ”€â”€ requirements.txt                 # Gerekli Python kÃ¼tÃ¼phaneleri
â””â”€â”€ README.md                        # Bu dosya
```

## ğŸš€ Kurulum

### Gereksinimler

- Python 3.7+
- NumPy
- Matplotlib

### AdÄ±mlar

1. Repoyu klonlayÄ±n veya indirin:
```bash
git clone https://github.com/ysntrkc/machine-learning-hw1.git
cd makine-ogrenmesi-hw1
```

2. (Opsiyonel) Sanal ortam oluÅŸturun ve aktifleÅŸtirin:
```bash
python -m venv venv
source venv/bin/activate  # Linux/MacOS
venv\Scripts\activate     # Windows
```

3. Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:
```bash
pip install -r requirements.txt
```

## ğŸ’» KullanÄ±m

### 1. Model EÄŸitimi

Modeli varsayÄ±lan parametrelerle eÄŸitmek iÃ§in:

```bash
cd src
python train.py
```

**Komut SatÄ±rÄ± ArgÃ¼manlarÄ±:**

```bash
python train.py [-lr LEARNING_RATE] [-e EPOCHS] [-p PATIENCE] [-d MIN_DELTA] [--no_early_stopping] [-l LOG_MODE]
```

- `-lr, --learning_rate`: Ã–ÄŸrenme oranÄ± (varsayÄ±lan: 0.01)
- `-e, --epochs`: Maksimum epoch sayÄ±sÄ± (varsayÄ±lan: 500)
- `-p, --patience`: Early stopping patience - iyileÅŸme olmadan beklenecek epoch sayÄ±sÄ± (varsayÄ±lan: 5)
- `-d, --min_delta`: Early stopping minimum delta - iyileÅŸme olarak kabul edilecek minimum deÄŸiÅŸim (varsayÄ±lan: 0.001)
- `--no_early_stopping`: Early stopping'i devre dÄ±ÅŸÄ± bÄ±rak
- `-l, --log`: Log modu (varsayÄ±lan: both)
  - `both`: Konsol ve dosyaya loglama
  - `console`: Sadece konsola loglama
  - `file`: Sadece dosyaya loglama

**Ã–rnek KullanÄ±m:**

```bash
# VarsayÄ±lan parametrelerle eÄŸitim (early stopping aktif)
python train.py

# Ã–zel learning rate ve epoch sayÄ±sÄ±
python train.py -lr 0.001 -e 200

# Early stopping parametrelerini Ã¶zelleÅŸtirme
python train.py -p 15 -d 0.0005

# Early stopping'i devre dÄ±ÅŸÄ± bÄ±rakma
python train.py --no_early_stopping

# Sadece konsola loglama
python train.py -l console

# TÃ¼m parametrelerle
python train.py -lr 0.005 -e 150 -p 20 -d 0.0001 -l file
```

Bu komut:
- Veriyi yÃ¼kler ve normalize eder
- Train/val/test setlerine ayÄ±rÄ±r (%60/%20/%20)
- Scatter plot grafikleri oluÅŸturur (tÃ¼m veri ve eÄŸitim verisi)
- Belirtilen epoch sayÄ±sÄ± boyunca SGD ile modeli eÄŸitir
- **Early stopping** ile eÄŸitimi izler:
  - Validation loss izlenir
  - Belirlenen patience sÃ¼resi boyunca iyileÅŸme olmazsa eÄŸitim durdurulur
  - En iyi validation loss'a sahip model aÄŸÄ±rlÄ±klarÄ± saklanÄ±r
  - Early stopping tetiklendiÄŸinde en iyi aÄŸÄ±rlÄ±klar geri yÃ¼klenir
- EÄŸitim ilerlemesini konsola ve/veya dosyaya loglar
- KayÄ±p grafiÄŸini oluÅŸturur (`results/graphs/loss_curve.png`)
- **Karar sÄ±nÄ±rÄ± grafiklerini oluÅŸturur** (`train_decision_boundary.png`, `val_decision_boundary.png`)
- Model aÄŸÄ±rlÄ±klarÄ±nÄ± iki versiyonda kaydeder:
  - Timestamp'li versiyon: `model_weights_YYYYMMDD_HHMMSS.npy`
  - Son model: `model_weights_latest.npy`
- EÄŸitim parametrelerini kaydeder (`results/model/training_params.json`)

### 2. Model DeÄŸerlendirme

EÄŸitilmiÅŸ modeli test setinde deÄŸerlendirmek iÃ§in:

```bash
python eval.py
```

**Komut SatÄ±rÄ± ArgÃ¼manlarÄ±:**

```bash
python eval.py [-l LOG_MODE]
```

- `-l, --log`: Log modu (varsayÄ±lan: both)
  - `both`: Konsol ve dosyaya loglama
  - `console`: Sadece konsola loglama
  - `file`: Sadece dosyaya loglama

**Ã–rnek KullanÄ±m:**

```bash
# VarsayÄ±lan (konsol ve dosyaya)
python eval.py

# Sadece konsola yazdÄ±rma
python eval.py -l console

# Sadece dosyaya kaydetme
python eval.py -l file
```

Bu komut ÅŸu metrikleri yazdÄ±rÄ±r:
- **EÄŸitim Parametreleri**: Modelin eÄŸitildiÄŸi parametreler (learning rate, epochs, early stopping bilgileri)
- **Loss (KayÄ±p)**: Cross-entropy loss
- **Accuracy (DoÄŸruluk)**: Genel doÄŸru tahmin oranÄ±
- **Precision (Kesinlik)**: Pozitif tahminlerin doÄŸruluk oranÄ±
- **Recall (DuyarlÄ±lÄ±k)**: GerÃ§ek pozitifleri bulma oranÄ±
- **F1 Score**: Precision ve recall'Ä±n harmonik ortalamasÄ±
- **Confusion Matrix**: DetaylÄ± tablo formatÄ±nda confusion matrix
- **Karar SÄ±nÄ±rÄ± GrafiÄŸi**: Test verisi Ã¼zerinde model karar sÄ±nÄ±rÄ± (`test_decision_boundary.png`)

### 3. Veri HazÄ±rlama (Opsiyonel)

Sadece veri Ã¶n iÅŸleme yapmak iÃ§in:

```bash
python dataset.py
```

## ğŸ“š ModÃ¼llerin DetaylÄ± AÃ§Ä±klamasÄ±

### 1. `dataset.py` - Veri Ä°ÅŸleme ModÃ¼lÃ¼

Bu modÃ¼l, veri yÃ¼kleme, normalizasyon ve bÃ¶lme iÅŸlemlerini gerÃ§ekleÅŸtirir.

#### Fonksiyonlar:

**`load_data(path)`**
- Ham veriyi TXT dosyasÄ±ndan ',' ile ayÄ±rÄ±r ve numPy dizisi olarak yÃ¼kler
- Ä°lk iki sÃ¼tun Ã¶zellikler (features), Ã¼Ã§Ã¼ncÃ¼ sÃ¼tun etiket (label)
- 101 Ã¶rnek, 2 Ã¶zellik, ikili sÄ±nÄ±flandÄ±rma (0/1)

**`normalize_features(X)`**
- Min-Max normalizasyonu uygular: `(X - min) / (max - min)`
- Her Ã¶zelliÄŸi [0, 1] aralÄ±ÄŸÄ±na Ã¶lÃ§ekler
- BÃ¶lme hatasÄ±nÄ± Ã¶nlemek iÃ§in Ã¶zel kontrol iÃ§erir

**`split_data(X, y, train_ratio=0.6, val_ratio=0.2)`**
- Veriyi **sÄ±ralÄ± olarak** Ã¼Ã§ sete bÃ¶ler:
  - EÄŸitim: Ä°lk %60 (60 Ã¶rnek)
  - DoÄŸrulama: Sonraki %20 (20 Ã¶rnek)
  - Test: Son %20 (21 Ã¶rnek)
- **Not**: Random shuffle yapÄ±lmaz, veri sÄ±ralÄ± bÃ¶lÃ¼nÃ¼r

**`save_splits(prefix, train_data, val_data, test_data)`**
- Train/val/test setlerini `.npz` formatÄ±nda sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ olarak kaydeder
- Her dosyada `X` (features) ve `y` (labels) arrays bulunur

**`prepare_and_save_data()`**
- Ana veri hazÄ±rlama pipeline'Ä±
- Hem ham hem de normalize edilmiÅŸ versiyonlarÄ± kaydeder
- Scatter plot grafikleri oluÅŸturur:
  - TÃ¼m verinin gÃ¶rselleÅŸtirmesi
  - EÄŸitim verisinin gÃ¶rselleÅŸtirmesi

### 2. `model.py` - Lojistik Regresyon Modeli

Lojistik regresyon algoritmasÄ±nÄ±n implementasyonu.

#### Fonksiyonlar:

**`sigmoid(z)`**
```python
Ïƒ(z) = 1 / (1 + e^(-z))
```
- Aktivasyon fonksiyonu
- [-âˆ, +âˆ] aralÄ±ÄŸÄ±nÄ± [0, 1] olasÄ±lÄ±k aralÄ±ÄŸÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r

**`predict_probabilities(X, w)`**
```python
p = Ïƒ(X Â· w)
```
- Ã–zellik matrisi ve aÄŸÄ±rlÄ±klar ile olasÄ±lÄ±k tahmini yapar
- Matris Ã§arpÄ±mÄ± sonrasÄ± sigmoid uygular

**`cross_entropy_loss(y_true, y_pred)`**
```python
L = -1/N Î£[yÂ·log(p) + (1-y)Â·log(1-p)]
```
- Ä°kili sÄ±nÄ±flandÄ±rma iÃ§in kayÄ±p fonksiyonu
- `epsilon=1e-15` ile log(0) hatasÄ±nÄ± Ã¶nler
- `np.mean` kullanarak batch size'dan baÄŸÄ±msÄ±z kayÄ±p hesaplar

**`caclulate_gradient(X_i, y_i_true, y_i_pred)`**
```python
âˆ‡L = (p - y) Â· X
```
- Tek bir Ã¶rnek iÃ§in gradyan hesaplar
- SGD iÃ§in gerekli tÃ¼rev

**`update_weights(w, gradient, learning_rate)`**
```python
w_new = w - Î· Â· âˆ‡L
```
- AÄŸÄ±rlÄ±klarÄ± gradyan descent ile gÃ¼nceller
- Î· (eta): Ã¶ÄŸrenme oranÄ±

**`initialize_weights(n_features)`**
- AÄŸÄ±rlÄ±klarÄ± [-0.01, 0.01] aralÄ±ÄŸÄ±nda rastgele baÅŸlatÄ±r
- KÃ¼Ã§Ã¼k deÄŸerler ile baÅŸlamak eÄŸitim stabilitesini artÄ±rÄ±r

### 3. `train.py` - Model EÄŸitimi

Lojistik regresyon modelini Stochastic Gradient Descent (SGD) ile eÄŸitir.

#### Ana Fonksiyon: `load_training_data`

**`load_training_data(path_prefix='../data/normalized')`**
- Normalize edilmiÅŸ eÄŸitim ve doÄŸrulama verilerini yÃ¼kler
- **Hata kontrolÃ¼**: EÄŸer veri dosyalarÄ± bulunamazsa `FileNotFoundError` fÄ±rlatÄ±r
- KullanÄ±cÄ±ya Ã¶nce veri hazÄ±rlamasÄ±nÄ± sÃ¶yleyen aÃ§Ä±klayÄ±cÄ± hata mesajÄ±

#### Ana Fonksiyon: `train_logistic_regression`

**Parametreler:**
- `learning_rate=0.01`: Ã–ÄŸrenme oranÄ±
- `n_epochs=500`: Epoch sayÄ±sÄ±
- `patience=5`: Early stopping patience - iyileÅŸme olmadan beklenecek epoch sayÄ±sÄ±
- `min_delta=0.001`: Early stopping iÃ§in minimum iyileÅŸme
- `early_stopping=True`: Early stopping'i etkinleÅŸtirir/devre dÄ±ÅŸÄ± bÄ±rakÄ±r

**SGD AlgoritmasÄ±:**
```
Her epoch iÃ§in:
    Her Ã¶rnek iÃ§in (tek tek):
        1. Forward pass: tahmin yap
        2. Loss hesapla
        3. Gradyan hesapla
        4. AÄŸÄ±rlÄ±klarÄ± gÃ¼ncelle
    Epoch sonu:
        1. Ortalama train loss hesapla
        2. TÃ¼m val seti ile val loss hesapla
        3. Early stopping kontrolÃ¼ yap
```

**Ã–zellikler:**
- **Bias Term**: Ã–zellik matrisine otomatik bias sÃ¼tunu eklenir (1'lerden oluÅŸan)
- **Batch-by-Batch**: Her Ã¶rnek tek tek iÅŸlenir (true SGD)
- **Dual Tracking**: Hem eÄŸitim hem doÄŸrulama kaybÄ± kaydedilir
- **Progress Monitoring**: Her epoch'ta kayÄ±plar yazdÄ±rÄ±lÄ±r

#### `add_bias_term(X)`
```python
X_bias = [1, x1, x2, ..., xn]  # Her satÄ±ra 1 eklenir
```
- Bias terimi ekler (w0 iÃ§in)
- n_features â†’ n_features + 1

### 4. `eval.py` - Model DeÄŸerlendirme

EÄŸitilmiÅŸ modeli test verisinde deÄŸerlendirir.

#### Ana Fonksiyon: `evaluate_model`

**DeÄŸerlendirme AdÄ±mlarÄ±:**
1. OlasÄ±lÄ±k tahminleri yap
2. Threshold=0.5 ile ikili sÄ±nÄ±f tahmini yap
3. TÃ¼m metrikleri hesapla

**DÃ¶nen Metrikler:**
- Loss
- Accuracy
- Precision
- Recall
- F1 Score

### 5. `metrics.py` - Performans Metrikleri

SÄ±nÄ±flandÄ±rma performans metriklerini hesaplar.

#### Confusion Matrix

```
            GerÃ§ek DeÄŸer
             1       0
Tahmin  1    TP      FN
Edilen  0    FP      TN
```

**`confusion_matrix(y_true, y_pred)`**
- True Positive (TP): DoÄŸru pozitif tahminler
- True Negative (TN): DoÄŸru negatif tahminler
- False Positive (FP): YanlÄ±ÅŸ pozitif tahminler (Type I error)
- False Negative (FN): YanlÄ±ÅŸ negatif tahminler (Type II error)

#### Metrikler

**`accuracy(y_true=None, y_pred=None, conf_matrix=None)`**
```python
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```
- Genel doÄŸruluk oranÄ±
- TÃ¼m doÄŸru tahminlerin oranÄ±
- **Ä°ki kullanÄ±m ÅŸekli:**
  1. `y_true` ve `y_pred` vererek: Otomatik confusion matrix hesaplar
  2. `conf_matrix` vererek: Ã–nceden hesaplanmÄ±ÅŸ confusion matrix kullanÄ±r (daha verimli)

**`precision(y_true=None, y_pred=None, conf_matrix=None)`**
```python
Precision = TP / (TP + FP)
```
- Pozitif tahminlerin ne kadarÄ± doÄŸru
- "Tahmin ettiÄŸim pozitiflerin gÃ¼venilirliÄŸi"
- **Ä°ki kullanÄ±m ÅŸekli:**
  1. `y_true` ve `y_pred` vererek
  2. `conf_matrix` vererek (daha verimli)

**`recall(y_true=None, y_pred=None, conf_matrix=None)`**
```python
Recall = TP / (TP + FN)
```
- GerÃ§ek pozitiflerin ne kadarÄ±nÄ± bulduk
- "TÃ¼m pozitifleri bulma yeteneÄŸim"
- **Ä°ki kullanÄ±m ÅŸekli:**
  1. `y_true` ve `y_pred` vererek
  2. `conf_matrix` vererek (daha verimli)

**`f1_score(y_true=None, y_pred=None, conf_matrix=None)`**
```python
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
```
- Precision ve Recall'Ä±n harmonik ortalamasÄ±
- Dengesiz veri setlerinde daha bilgilendirici
- **Ä°ki kullanÄ±m ÅŸekli:**
  1. `y_true` ve `y_pred` vererek
  2. `conf_matrix` vererek (daha verimli)

**Ã–zel Durumlar:**
- TÃ¼m fonksiyonlar division by zero kontrolÃ¼ iÃ§erir
- TanÄ±msÄ±z durumlarda 0.0 dÃ¶ner
- `conf_matrix` parametresi kullanÄ±ldÄ±ÄŸÄ±nda daha verimli Ã§alÄ±ÅŸÄ±r (confusion matrix'i tekrar hesaplamaz)

**KullanÄ±m Ã–rneÄŸi:**
```python
# Metod 1: y_true ve y_pred ile
acc = accuracy(y_true, y_pred)

# Metod 2: Ã–nceden hesaplanmÄ±ÅŸ confusion matrix ile (daha verimli)
conf_mat = confusion_matrix(y_true, y_pred)
acc = accuracy(conf_matrix=conf_mat)
prec = precision(conf_matrix=conf_mat)
rec = recall(conf_matrix=conf_mat)
f1 = f1_score(conf_matrix=conf_mat)
```

### 6. `utils.py` - YardÄ±mcÄ± Fonksiyonlar

GÃ¶rselleÅŸtirme ve dosya yÃ¶netimi fonksiyonlarÄ±.

#### `ensure_dir_exists(directory)`
- Dizin yoksa oluÅŸturur
- `os.makedirs()` ile recursive oluÅŸturma

#### `plot_scatter(X, y, data='tÃ¼m', save_path='../results/graphs/')`
- Veriyi 2D scatter plot olarak Ã§izer
- Ä°ki sÄ±nÄ±fÄ± farklÄ± renklerle gÃ¶sterir:
  - **Kalanlar (Class 0)**: KÄ±rmÄ±zÄ± 'x' - SÄ±navdan kalan adaylar
  - **GeÃ§enler (Class 1)**: Mavi 'o' - SÄ±navdan geÃ§en adaylar
- Eksen etiketleri: "SÄ±nav 1" ve "SÄ±nav 2"
- Bias sÃ¼tununu otomatik atlar
- Grafik dosya adÄ±: `{data}_scatter_plot.png`
- VarsayÄ±lan kayÄ±t yolu: `../results/graphs/`

#### `plot_loss_curve(train_losses, val_losses, save_path='../results/graphs/')`
- EÄŸitim ve doÄŸrulama kayÄ±plarÄ±nÄ± epoch'a gÃ¶re Ã§izer
- Overfitting/underfitting tespiti iÃ§in kritik
- Ä°ki eÄŸriyi aynÄ± grafikte gÃ¶sterir
- Grafik dosya adÄ±: `loss_curve.png`
- VarsayÄ±lan kayÄ±t yolu: `../results/graphs/`

#### `plot_decision_boundary(X_normalized, y, weights, X_raw, data='test', save_path='../results/graphs/')`
- Veri noktalarÄ±nÄ± ve lojistik regresyon karar sÄ±nÄ±rÄ±nÄ± birlikte Ã§izer
- **Orijinal (normalize edilmemiÅŸ) deÄŸerleri kullanÄ±r** - daha anlaÅŸÄ±lÄ±r gÃ¶rselleÅŸtirme
- **Karar SÄ±nÄ±rÄ± Hesaplama:**
  - Model normalize edilmiÅŸ verilerle eÄŸitilir: `w0 + w1*x1_norm + w2*x2_norm = 0`
  - Karar sÄ±nÄ±rÄ± orijinal Ã¶lÃ§eÄŸe dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r
  - Bu doÄŸru, sigmoid fonksiyonunun 0.5 deÄŸerini aldÄ±ÄŸÄ± noktalarÄ± gÃ¶sterir
  - DoÄŸrunun Ã¼stÃ¼ndeki noktalar Class 1, altÄ±ndakiler Class 0 olarak tahmin edilir
- **Parametreler:**
  - `X_normalized`: Normalize edilmiÅŸ Ã¶zellik matrisi (bias terimi iÃ§erebilir)
  - `y`: GerÃ§ek etiketler
  - `weights`: Model aÄŸÄ±rlÄ±klarÄ± [w0 (bias), w1, w2]
  - `X_raw`: Ham (normalize edilmemiÅŸ) Ã¶zellik matrisi
  - `data`: Veri seti tÃ¼rÃ¼ (grafik baÅŸlÄ±ÄŸÄ± iÃ§in)
- **GÃ¶rselleÅŸtirme:**
  - KÄ±rmÄ±zÄ± 'x': Kalanlar (Class 0)
  - Mavi 'o': GeÃ§enler (Class 1)
  - YeÅŸil Ã§izgi: Karar sÄ±nÄ±rÄ± (Decision Boundary)
  - Eksen etiketleri: "SÄ±nav 1" ve "SÄ±nav 2" (orijinal deÄŸerler)
- Grafik dosya adÄ±: `{data}_decision_boundary.png`
- YÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼k (150 DPI)
- EÄŸitim sonrasÄ± otomatik olarak train, val ve test setleri iÃ§in oluÅŸturulur

#### `save_weights(w, save_dir='../results/model/')`
- Model aÄŸÄ±rlÄ±klarÄ±nÄ± `.npy` formatÄ±nda kaydeder
- **Ä°ki ayrÄ± dosya olarak kaydeder**:
  1. Timestamp ile isimlendirilen versiyon: `model_weights_YYYYMMDD_HHMMSS.npy`
  2. En son model: `model_weights_latest.npy` (her eÄŸitimde Ã¼zerine yazÄ±lÄ±r)
- VarsayÄ±lan kayÄ±t yolu: `../results/model/`
- Timestamp'li versiyon farklÄ± eÄŸitimleri karÄ±ÅŸtÄ±rmadan saklar

#### `parse_training_args()`
- Komut satÄ±rÄ± argÃ¼manlarÄ±nÄ± parse eder
- Desteklenen argÃ¼manlar:
  - `-lr, --learning_rate`: Ã–ÄŸrenme oranÄ± (float, varsayÄ±lan: 0.01)
  - `-e, --epochs`: Maksimum epoch sayÄ±sÄ± (int, varsayÄ±lan: 100)
  - `-p, --patience`: Early stopping patience (int, varsayÄ±lan: 10)
  - `-d, --min_delta`: Early stopping minimum delta (float, varsayÄ±lan: 0.0001)
  - `--no_early_stopping`: Early stopping'i devre dÄ±ÅŸÄ± bÄ±rak (flag)
  - `-l, --log`: Log modu (str, varsayÄ±lan: "both")
- `argparse.Namespace` objesi dÃ¶ndÃ¼rÃ¼r

#### `print_training_config(learning_rate, n_epochs, patience, min_delta, early_stopping_enabled)`
- EÄŸitim konfigÃ¼rasyonunu formatlÄ± ÅŸekilde ekrana yazdÄ±rÄ±r
- GÃ¶sterilen bilgiler:
  - Learning rate
  - Epoch sayÄ±sÄ±
  - Early stopping durumu (aktif/devre dÄ±ÅŸÄ±)
  - Early stopping parametreleri (patience, min_delta)
- EÄŸitim baÅŸlamadan Ã¶nce Ã§aÄŸrÄ±lÄ±r

#### `save_training_params(learning_rate, n_epochs, actual_epochs, patience, min_delta, early_stopping_enabled, early_stopped, save_file='../results/model/training_params.json')`
- EÄŸitim parametrelerini JSON formatÄ±nda kaydeder
- Kaydedilen bilgiler:
  - `learning_rate`: Ã–ÄŸrenme oranÄ±
  - `max_epochs`: Maksimum epoch sayÄ±sÄ±
  - `actual_epochs`: GerÃ§ekleÅŸen epoch sayÄ±sÄ±
  - `early_stopping_enabled`: Early stopping kullanÄ±ldÄ± mÄ±
  - `early_stopped`: Early stopping tetiklendi mi
  - `patience`: Early stopping patience
  - `min_delta`: Early stopping minimum delta
  - `timestamp`: EÄŸitim tarihi ve saati
- Evaluation sÄ±rasÄ±nda bu parametreler otomatik olarak gÃ¶sterilir

#### `load_training_params(load_file='../results/model/training_params.json')`
- KaydedilmiÅŸ eÄŸitim parametrelerini yÃ¼kler
- JSON dosyasÄ±nÄ± okur ve dictionary dÃ¶ndÃ¼rÃ¼r
- Dosya yoksa `None` dÃ¶ndÃ¼rÃ¼r
- `eval.py` tarafÄ±ndan test sonuÃ§larÄ±nÄ± gÃ¶sterirken kullanÄ±lÄ±r

#### `print_confusion_matrix(conf_matrix)`
- Confusion matrix'i tablo formatÄ±nda gÃ¶rselleÅŸtirir
- TP, TN, FP, FN deÄŸerlerini gÃ¶sterir
- Ã–zet bilgiler:
  - Toplam Ã¶rnek sayÄ±sÄ±
  - GerÃ§ek pozitif/negatif sayÄ±larÄ±
  - Tahmin pozitif/negatif sayÄ±larÄ±
- KullanÄ±cÄ± dostu tablo formatÄ±

#### `log_test_results(results, log_file='../results/evaluation/test_results.txt')`
- Test sonuÃ§larÄ±nÄ± dosyaya kaydeder
- Timestamp ile birlikte kaydedilir
- TÃ¼m metrikleri (loss, accuracy, precision, recall, f1_score) iÃ§erir

### 7. `logger.py` - BirleÅŸik Loglama Sistemi

Proje genelinde birleÅŸik loglama saÄŸlayan modÃ¼l. Konsola, dosyaya veya her ikisine birden loglama yapabilir.

#### `Logger` SÄ±nÄ±fÄ±

**`__init__(log_file='../results/logs/training.log', mode='both')`**
- Loglama sistemi iÃ§in ana sÄ±nÄ±f
- **Parametreler:**
  - `log_file`: Log dosyasÄ±nÄ±n yolu
  - `mode`: Loglama modu
    - `"both"`: Hem konsol hem dosya
    - `"console"`: Sadece konsol
    - `"file"`: Sadece dosya
- Context manager destekler (`with` statement)

**`log(message, end='\n')`**
- MesajÄ± seÃ§ilen moda gÃ¶re loglar
- `print()` gibi Ã§alÄ±ÅŸÄ±r ama dosyaya da yazar
- Otomatik flush ile anÄ±nda yazma

**`close()`**
- Log dosyasÄ±nÄ± kapatÄ±r
- KaynaklarÄ± temizler

#### YardÄ±mcÄ± Fonksiyonlar:

**`setup_logger(log_file='../results/logs/training.log', mode='both')`**
- Global logger instance'Ä± oluÅŸturur ve yapÄ±landÄ±rÄ±r
- Ã–nceki logger varsa kapatÄ±r ve yenisini oluÅŸturur
- Train ve eval modÃ¼lleri tarafÄ±ndan kullanÄ±lÄ±r

**`get_logger()`**
- Global logger instance'Ä±nÄ± dÃ¶ndÃ¼rÃ¼r
- Yoksa otomatik olarak oluÅŸturur

**`log(message, end='\n')`**
- KolaylÄ±k fonksiyonu
- Global logger'Ä± kullanarak mesaj loglar
- TÃ¼m modÃ¼llerde `from logger import log` ile import edilir

**KullanÄ±m Ã–rneÄŸi:**
```python
from logger import setup_logger, log

# Logger'Ä± yapÄ±landÄ±r
setup_logger(mode='both')

# Log kullan
log("Training started")
log(f"Epoch {epoch}: Loss = {loss:.4f}")
```

## ğŸ§® Algoritma DetaylarÄ±

### Lojistik Regresyon MatematiÄŸi

#### 1. Hipotez Fonksiyonu
```
h(x) = Ïƒ(w^T Â· x) = 1 / (1 + e^(-w^TÂ·x))
```

#### 2. Karar KuralÄ±
```
y_pred = 1  if h(x) â‰¥ 0.5
y_pred = 0  if h(x) < 0.5
```

#### 3. KayÄ±p Fonksiyonu (Cross-Entropy)
```
L(w) = -1/m Î£[y^(i) log(h(x^(i))) + (1-y^(i)) log(1-h(x^(i)))]
```

#### 4. Gradyan
```
âˆ‚L/âˆ‚w = 1/m Î£[(h(x^(i)) - y^(i)) Â· x^(i)]
```

#### 5. GÃ¼ncelleme KuralÄ± (SGD)
```
w := w - Î· Â· (h(x^(i)) - y^(i)) Â· x^(i)
```

### Stochastic Gradient Descent (SGD)

Bu implementasyon **true SGD** kullanÄ±r:
- Her Ã¶rnekte aÄŸÄ±rlÄ±k gÃ¼ncellenir
- Mini-batch veya batch GD deÄŸil

### Early Stopping

**Overfitting'i Ã¶nlemek** iÃ§in validation loss bazlÄ± early stopping kullanÄ±lÄ±r:

#### Parametreler:
- **patience**: Ä°yileÅŸme olmadan beklenecek epoch sayÄ±sÄ± (varsayÄ±lan: 10)
- **min_delta**: Ä°yileÅŸme olarak kabul edilecek minimum deÄŸiÅŸim (varsayÄ±lan: 0.0001)

#### Algoritma:
```
Her epoch sonunda:
    EÄŸer (val_loss < best_val_loss - min_delta):
        best_val_loss = val_loss
        best_weights = current_weights
        epochs_no_improve = 0
    DeÄŸilse:
        epochs_no_improve += 1
    
    EÄŸer (epochs_no_improve >= patience):
        EÄŸitimi durdur
        best_weights'i geri yÃ¼kle
```

#### Log Ã‡Ä±ktÄ±sÄ±:
```
Epoch  50/100 - Train Loss: 0.3245 - Val Loss: 0.3412 * - No Improve: 0
Epoch  60/100 - Train Loss: 0.3201 - Val Loss: 0.3445   - No Improve: 10

==================================================
Early stopping triggered at epoch 60
Best validation loss: 0.3412
Restoring best weights from epoch 50
==================================================
```

**Not:** `*` iÅŸareti validation loss'ta iyileÅŸme olduÄŸunu gÃ¶sterir.

### Normalizasyon

**Min-Max Scaling** kullanÄ±lÄ±r:
```
X_norm = (X - X_min) / (X_max - X_min)
```

**Neden Normalizasyon?**
- FarklÄ± Ã¶lÃ§eklerdeki Ã¶zellikleri eÅŸitler
- Gradyan descent'i hÄ±zlandÄ±rÄ±r
- SayÄ±sal stabiliteyi artÄ±rÄ±r
- Ã–ÄŸrenme oranÄ± seÃ§imini kolaylaÅŸtÄ±rÄ±r

## ğŸ“Š SonuÃ§lar

### Model PerformansÄ±

Model baÅŸarÄ±lÄ± ÅŸekilde eÄŸitilir ve ÅŸu metrikler hesaplanÄ±r:

- **Accuracy**: Genel doÄŸruluk oranÄ±
- **Precision**: Pozitif tahminlerin gÃ¼venilirliÄŸi
- **Recall**: TÃ¼m pozitifleri yakalama oranÄ±
- **F1 Score**: Precision ve recall dengesi

### Ã‡Ä±ktÄ± DosyalarÄ±

1. **Scatter Plots** (`results/graphs/`)
   - `tÃ¼m_scatter_plot.png`: TÃ¼m veri setinin gÃ¶rselleÅŸtirmesi
   - `train_scatter_plot.png`: EÄŸitim verisinin gÃ¶rselleÅŸtirmesi
   - Her sÄ±nÄ±f farklÄ± renk ve iÅŸaretle gÃ¶sterilir
   - Eksenler: SÄ±nav 1 ve SÄ±nav 2 skorlarÄ±

2. **Decision Boundary Plots** (`results/graphs/`)
   - `train_decision_boundary.png`: EÄŸitim verisi Ã¼zerinde karar sÄ±nÄ±rÄ±
   - `val_decision_boundary.png`: DoÄŸrulama verisi Ã¼zerinde karar sÄ±nÄ±rÄ±
   - `test_decision_boundary.png`: Test verisi Ã¼zerinde karar sÄ±nÄ±rÄ±
   - YeÅŸil Ã§izgi: Lojistik regresyon karar sÄ±nÄ±rÄ± (decision boundary)
   - KÄ±rmÄ±zÄ± 'x': Kalanlar (Class 0)
   - Mavi 'o': GeÃ§enler (Class 1)
   - **Orijinal (normalize edilmemiÅŸ) SÄ±nav 1 ve SÄ±nav 2 skorlarÄ± kullanÄ±lÄ±r**
   - Modelin sÄ±nÄ±flarÄ± nasÄ±l ayÄ±rdÄ±ÄŸÄ±nÄ± gÃ¶rsel olarak gÃ¶sterir
   - Karar sÄ±nÄ±rÄ± normalize edilmiÅŸ modelden hesaplanÄ±r ve orijinal Ã¶lÃ§eÄŸe dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r

3. **Loss Curve** (`results/graphs/loss_curve.png`)
   - EÄŸitim ve doÄŸrulama kayÄ±plarÄ±nÄ±n epoch'a gÃ¶re deÄŸiÅŸimi
   - Overfitting kontrolÃ¼ iÃ§in kullanÄ±lÄ±r
   - Mavi: EÄŸitim kaybÄ±, Turuncu: DoÄŸrulama kaybÄ±

4. **Model Weights** (`results/model/`)
   - `model_weights_YYYYMMDD_HHMMSS.npy`: Timestamp'li versiyon
   - `model_weights_latest.npy`: En son eÄŸitilmiÅŸ model
   - Her ikisi de `numpy.load()` ile yÃ¼klenebilir
   - Timestamp'li versiyon her Ã§alÄ±ÅŸtÄ±rmada yeni dosya oluÅŸturur
   - Latest versiyon her eÄŸitimde gÃ¼ncellenir

5. **Training Parameters** (`results/model/training_params.json`)
   - EÄŸitim parametrelerini JSON formatÄ±nda saklar
   - Ä°Ã§erik:
     - `learning_rate`: Ã–ÄŸrenme oranÄ±
     - `max_epochs`: Maksimum epoch sayÄ±sÄ±
     - `actual_epochs`: GerÃ§ekleÅŸen epoch sayÄ±sÄ±
     - `early_stopping_enabled`: Early stopping kullanÄ±ldÄ± mÄ±
     - `early_stopped`: Early stopping tetiklendi mi
     - `patience`: Early stopping patience deÄŸeri
     - `min_delta`: Early stopping minimum delta deÄŸeri
     - `timestamp`: EÄŸitim zamanÄ±
   - Test sonuÃ§larÄ± yazdÄ±rÄ±lÄ±rken otomatik olarak gÃ¶sterilir
   - Latest versiyon her eÄŸitimde gÃ¼ncellenir

## ğŸ“ Notlar

### Veri Seti Ã–zellikleri
- **Toplam Ã¶rnek**: 101
- **Ã–zellik sayÄ±sÄ±**: 2 (SÄ±nav 1 ve SÄ±nav 2 skorlarÄ±)
- **SÄ±nÄ±f sayÄ±sÄ±**: 2 (binary classification)
  - **Class 0**: Kalanlar (sÄ±navdan geÃ§emeyen adaylar)
  - **Class 1**: GeÃ§enler (sÄ±navdan geÃ§en adaylar)
- **Format**: CSV (virgÃ¼lle ayrÄ±lmÄ±ÅŸ)
- **Split**: 60-20-20 (train-val-test)
- **Dosya yollarÄ±**: GÃ¶reli yollar kullanÄ±lÄ±r (`../data/`, `../results/`)

### Hiperparametreler
- **Learning Rate**: 0.01 (Ã¶zelleÅŸtirilebilir: `-lr` flag)
- **Max Epochs**: 500 (Ã¶zelleÅŸtirilebilir: `-e` flag)
- **Early Stopping**: Aktif (devre dÄ±ÅŸÄ± bÄ±rakÄ±labilir: `--no_early_stopping` flag)
  - **Patience**: 5 (Ã¶zelleÅŸtirilebilir: `-p` flag)
  - **Min Delta**: 0.001 (Ã¶zelleÅŸtirilebilir: `-d` flag)
- **Weight Initialization**: Uniform(-0.01, 0.01)
- **Threshold**: 0.5 (classification)
- **Epsilon**: 1e-15 (numerical stability)
